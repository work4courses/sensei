{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "%cd /content/drive/My\\ Drive/\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmNA33U7ol_q"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from itertools import *\n",
    "import itertools\n",
    "import time\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from sklearn import preprocessing\n",
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "##import .py files\n",
    "import evaluate\n",
    "import importlib\n",
    "importlib.reload(evaluate)\n",
    "\n",
    "startTotal = time.time()\n",
    "\n",
    "def getModel(x_size, x_train, y_train):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(64, input_dim=x_size, activation='relu'))\n",
    "  # model.add(Dropout(0.5))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  # model.add(Dropout(0.5))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "  callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss')]\n",
    "\n",
    "  model.fit(x_train, y_train, epochs=100, callbacks=callbacks, batch_size=32, validation_split=0.1, verbose=0) #default shuffle\n",
    "\n",
    "  return model\n",
    "\n",
    "## set up\n",
    "dataset = 'sod'\n",
    "frac = 100\n",
    "version = 0\n",
    "direction = 'Backward' #Forward Backward Two Bi\n",
    "if dataset == 'pku' or dataset == 'msr':\n",
    "  nameData = 'nameOri'\n",
    "else:\n",
    "  nameData = 'nameNon'\n",
    "labelSeg = 'labelSeg'\n",
    "if direction == 'Forward':\n",
    "  rnnSize = 128\n",
    "  embSize = 128\n",
    "  cellSize = str(rnnSize)+'_'+str(embSize)\n",
    "elif direction == 'Backward':\n",
    "  rnnSize = 16\n",
    "  embSize = 32\n",
    "  cellSize = str(rnnSize)+'_'+str(embSize)\n",
    "\n",
    "savePath = [direction, cellSize, 'V'+str(version)]\n",
    "\n",
    "info = {}\n",
    "info['dataset'] = dataset\n",
    "info['frac'] = frac\n",
    "info['version'] = version\n",
    "info['direction'] = direction\n",
    "info['rnnSize'] = rnnSize\n",
    "info['embSize'] = embSize\n",
    "pickle.dump(info, open( './data/'+dataset+'/info/'+''.join(savePath)+'.p', \"wb\" ))\n",
    "\n",
    "## data\n",
    "d = pickle.load(open( './data/'+dataset+'/'+dataset+'.p', \"rb\" ))\n",
    "d = d.sample(frac=1, random_state=version)\n",
    "\n",
    "if frac != 100:\n",
    "  dataset = dataset + str(frac)\n",
    "  d = d[:int(len(d)*(frac/100))]\n",
    "\n",
    "train = d\n",
    "test = d\n",
    "info['sampleLen'] = len(d)\n",
    "print('num of samples = {}'.format(len(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YxNnT91cC6C"
   },
   "source": [
    "# LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXMtrO_m1ZIA"
   },
   "outputs": [],
   "source": [
    "def toFile(inputFile, filename, direction='Forward', padding=False, maxLength=30):\n",
    "  if direction == 'Backward':\n",
    "    if padding:\n",
    "      inputFile = inputFile.apply(lambda x: '$'*(maxLength-len(x))+x).values.tolist()\n",
    "      assert all([len(x)==maxLength for x in inputFile])\n",
    "      \n",
    "    inputFile = '^$'.join(inputFile)\n",
    "    inputFile = '$'+inputFile+'^'\n",
    "    inputFile = inputFile[::-1]\n",
    "  else:\n",
    "    if padding:\n",
    "      inputFile = inputFile.apply(lambda x: x+'$'*(maxLength-len(x))).values.tolist()\n",
    "      assert all([len(x)==maxLength for x in inputFile])\n",
    "    inputFile = '$^'.join(inputFile)\n",
    "    inputFile = '^'+inputFile+'$'\n",
    "  \n",
    "  with open('./data/'+filename, \"w\") as f: #w,r,a\n",
    "    f.write(inputFile)\n",
    "\n",
    "  return len(inputFile)\n",
    "\n",
    "maxLength = max(d[nameData].apply(lambda x: len(x)).values.tolist())\n",
    "\n",
    "fileLen = toFile(train[nameData], dataset+'/input.txt', direction=direction, padding=True, maxLength=maxLength)\n",
    "info['inputFileLen'] = fileLen\n",
    "print('length of {} = {}'.format(dataset+'/input.txt',fileLen))\n",
    "\n",
    "fileLen = toFile(test[nameData],  dataset+'/test.txt', direction=direction, padding=False, maxLength=maxLength)\n",
    "info['outputFileLen'] = fileLen\n",
    "print('length of {} = {}'.format(dataset+'/test.txt', fileLen))\n",
    "\n",
    "assert info['inputFileLen'] >= info['outputFileLen']\n",
    "\n",
    "maxLength += 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtcpTI1A24Dz"
   },
   "source": [
    "### LM-Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PStDfgV1EMW5"
   },
   "outputs": [],
   "source": [
    "if direction == 'Forward':\n",
    "  rnnSizeList = [rnnSize]\n",
    "  embSizeList = [embSize]\n",
    "elif direction == 'Backward':\n",
    "  rnnSizeList = [rnnSize]\n",
    "  embSizeList = [embSize]\n",
    "save_dir = './save/'+'/'.join([dataset,direction,cellSize])\n",
    "temp = ''.join(savePath)\n",
    "start = time.time()\n",
    "for rnnSize in rnnSizeList:\n",
    "  for embSize in embSizeList:\n",
    "    cellSize = str(rnnSize) + '_' + str(embSize)\n",
    "    #learn\n",
    "    !python train.py --num_epochs=100 --data_dir=./data/$dataset --info_dir='./data/'$dataset'/info/'$temp'.p' --save_dir=$save_dir --rnn_size=$rnnSize --emb_size=$embSize --seq_length=$maxLength \n",
    "    #sample\n",
    "    !python sample.py --task='corpus_all' --save_path=$temp --save_dir=$save_dir --dataset=$dataset --seq_length=$maxLength\n",
    "end = time.time()\n",
    "info = pickle.load(open('./data/'+dataset+'/info/'+''.join(savePath)+'.p' , 'rb' ))\n",
    "info['LmRuntime'] = (end-start)/60\n",
    "print('time=',(end-start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eM_hZBvOt3hZ"
   },
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruFA6zq41yV0"
   },
   "source": [
    "### Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPlQ643dra6w"
   },
   "outputs": [],
   "source": [
    "showFig = False\n",
    "showGT = False\n",
    "dTest = pickle.load(open( './data/'+dataset+'/test/'+''.join(savePath)+'.p', \"rb\" ))\n",
    "eva = evaluate.EVA(test=test, dTest=dTest,nameData=nameData, labelSeg=labelSeg, direction=direction)\n",
    "test = eva.test\n",
    "split = 0\n",
    "eDev = eva.dTest[int(len(eva.dTest)*split):]\n",
    "precision = 3\n",
    "thresholds = np.arange(round(0.1**precision,precision),1,round(0.1**precision,precision))\n",
    "thresholdValues, _ = np.histogram(eDev['nextP'].values.tolist(),bins=thresholds, density=False)\n",
    "thresholdValues = thresholdValues/1000\n",
    "mid = int((len(thresholds)+1)/2)\n",
    "offset = int((len(thresholds)+1)*0.05)\n",
    "t1 = (2+np.argmax(thresholdValues[mid+offset-2:-offset-2])-2+mid+offset)/(len(thresholds)+1) #[550,950]\n",
    "t0 = (2+np.argmax(thresholdValues[offset-2:150-2])-2+offset)/(len(thresholds)+1) #[50,150]\n",
    "info['t1'] = t1\n",
    "info['t0'] = t0\n",
    "print('t1=', t1,'t0=', t0)\n",
    "\n",
    "if dataset == 'pku' or dataset == 'msr':\n",
    "  t1=0.3\n",
    "  t0 = 0.01\n",
    "if showFig:\n",
    "  fig, ax1 = plt.subplots()\n",
    "  ax2 = ax1.twinx()\n",
    "  ax2.plot(thresholds[1:], thresholdValues,color='red',lw=1,label='Probability Density Function', alpha=0.7)\n",
    "  if showGT:\n",
    "    dStats = pickle.load(open('./data/'+dataset+'/'+direction+'V'+str(version)+'GS.p', 'rb' ))\n",
    "    ax1.plot(thresholds, dStats['F1List'],color='green',lw=1)\n",
    "    ax1.vlines(dStats['bestThreshold'], 0, 1,lw=2, colors='black',linestyles='dotted',label='The Best Threshold')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0O8lpvrVZrdA"
   },
   "outputs": [],
   "source": [
    "def FW(method='Stats'):\n",
    "  global rnnSize,embSize\n",
    "\n",
    "  if method == 'Stats':\n",
    "    thresholds = [t1]\n",
    "    split = 0\n",
    "  elif method == 'GS':\n",
    "    thresholds = np.arange(round(0.1**precision,precision),1,round(0.1**precision,precision))\n",
    "    split = 0\n",
    "  elif method == 'GSSplit':\n",
    "    thresholds = np.arange(round(0.1**precision,precision),1,round(0.1**precision,precision))\n",
    "    split = 0.2\n",
    "\n",
    "  eva = evaluate.EVA(test=test, dTest=dTest, direction=direction, savePath=dataset+'/'+direction+'V'+str(version),nameData=nameData) #nameData=nameData, labelSeg=labelSeg\n",
    "  results = eva.reportByThresholds(thresholds, split=split, verbose=2, ignore=2)\n",
    "\n",
    "  if method == 'GS':\n",
    "    info['bestThreshold'] = results[-1]\n",
    "    info['GS'] = results\n",
    "  elif method == 'Stats':\n",
    "    info['Stats'] = results\n",
    "\n",
    "  print(method, results)\n",
    "  \n",
    "\n",
    "FW(method='Stats')\n",
    "FW(method='GS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8o1Z1FW16XB"
   },
   "source": [
    "### Ensemble-Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poJ5BkaTsp-3"
   },
   "outputs": [],
   "source": [
    "thresholds1 = [t1]\n",
    "thresholds0 = [t0]\n",
    "boost=True\n",
    "\n",
    "start = time.time()\n",
    "split = 0\n",
    "\n",
    "x_test = np.stack(eDev['hidden'].values)\n",
    "x_size = len(eDev.iloc[0]['hidden'])\n",
    "\n",
    "if boost:\n",
    "  T=100\n",
    "  frac = 0.1\n",
    "else:\n",
    "  T=1\n",
    "  frac = 1\n",
    "\n",
    "best = [((0,),),]\n",
    "\n",
    "for t1 in thresholds1:\n",
    "\n",
    "  dTest1 = eDev[eDev['nextP']>=t1]\n",
    "  len1 = len(dTest1)\n",
    "  # if len1 <= n_least:\n",
    "  #   continue\n",
    "\n",
    "  dTest1['next'] = [1]*len1\n",
    "\n",
    "  for t0 in thresholds0:\n",
    "\n",
    "    dTest0 = eDev[eDev['nextP']<=t0] #& (eDev['nextP']>0)\n",
    "    len0 = len(dTest0)\n",
    "    # if len0 <= n_least:\n",
    "    #   continue\n",
    "    dTest0['next'] = [0]*len0\n",
    "\n",
    "    \n",
    "    n0 = int(min(len1,len0)*frac)\n",
    "    n1 = n0\n",
    "\n",
    "    predList = []\n",
    "    for i in range(T):\n",
    "\n",
    "      train = pd.concat([dTest0.sample(n=n0, random_state=i) \n",
    "      , dTest1.sample(n=n1, random_state=i)]) \n",
    "\n",
    "      x_train = np.stack(train['hidden'].values)\n",
    "      y_train = np.stack(train['next'].values)\n",
    "\n",
    "\n",
    "      model = getModel(x_size, x_train, y_train)\n",
    "      # model.save('./save/'+dataset+'/'+direction+'/'+cellSize+'/'+i+'.h5')\n",
    "      pred = model.predict(x_test)\n",
    "      predList.append(pred)\n",
    "      del model  # deletes the existing model\n",
    "      # model = load_model('./save/'+dataset+'/'+direction+'/'+cellSize+'/'+i+'.h5')\n",
    "\n",
    "    eDev['next'] = np.mean(predList, axis=0)\n",
    "    eva.dTest = eDev.copy()\n",
    "\n",
    "    thresholds = [0.5]\n",
    "\n",
    "    results = eva.reportByThresholds(thresholds, split=split, verbose=2, ignore=2)\n",
    "    end = time.time()\n",
    "    print('time=',(end-start)/60)\n",
    "    params = [t1, t0, len1, len0, n1, n0, frac, boost]\n",
    "    print('results={}, params={}'.format(results, params))\n",
    "    \n",
    "    if results[0][0] > best[0][0][0]:\n",
    "      best = [results,params]\n",
    "\n",
    "info['bestRuntime'] = (end-start)/60\n",
    "info['best'] = [best[0], best[1]]\n",
    "print('best: results={}, params={}'.format(best[0], best[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save and final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDTET_Kfu2p2"
   },
   "outputs": [],
   "source": [
    "## hyperparameters and results\n",
    "pickle.dump(info, open('./data/'+dataset+'/test/'+''.join(savePath)+'.p', \"wb\" ))\n",
    "print(info)\n",
    "## error analysis\n",
    "dEval = eva.showSeg('predIgnore')\n",
    "pickle.dump(dEval, open('./data/'+dataset+'/test/'+''.join(savePath)+'.p', \"wb\" ))\n",
    "dEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DT3L8q9123Bm"
   },
   "outputs": [],
   "source": [
    "endTotal = time.time()\n",
    "print('totalTime=',(endTotal-startTotal)/60)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "concise.ipynb",
   "provenance": [
    {
     "file_id": "1cZHLTBgxU3Gd7S-8CdkGrIXoZNvW5Zgd",
     "timestamp": 1570765987168
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
